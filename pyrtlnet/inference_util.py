import argparse
import pathlib
import typing

import numpy as np


def add_common_arguments(parser: argparse.ArgumentParser) -> None:
    """Add common command line arguments supported by all inference scripts to a
    :class:`~argparse.ArgumentParser`.

    This defines all the shared command line flags in one place, so it's easier to keep
    them in sync.

    :param parser: Parser to add arguments to.
    """
    parser.add_argument(
        "--start_image",
        type=int,
        default=0,
        help="""Index of the first image to run in the MNIST test data set. Must be
             less than the number of images in the test data set (10000).
             """,
    )
    parser.add_argument(
        "--num_images",
        type=int,
        default=1,
        help="""Number of images to run. If the last image in the MNIST test data set is
             reached, processing will stop. When processing stops this way, fewer than
             `num_images` may be processed.
             """,
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=1,
        help="""Number of images to process per batch. If `batch_size > num_images`, the
             model will process up to `num_images`. If `num_images %% batch_size != 0`,
             the last batch will be of size `num_images %% batch_size`.
             """,
    )
    parser.add_argument(
        "--tensor_path",
        type=str,
        default=".",
        help="""Name of the directory containing the quantized weights and preprocessed
             MNIST test data produced by `tensorflow_training.py`.
             """,
    )
    parser.add_argument("--verbose", action=argparse.BooleanOptionalAction)


def load_mnist_data(tensor_path: str) -> tuple[np.ndarray, np.ndarray]:
    """Load MNIST test data and labels from ``mnist_test_data.npz``.

    ``mnist_test_data.npz`` contains a saved copy of the preprocessed MNIST image data
    and its corresponding labels. This ``.npz`` file is generated by
    ``tensorflow_training.py``, after evaluating the trained model. Loading this
    ``.npz`` file is much faster than calling :func:`.load_mnist_images`.

    :param tensor_path: Path to ``mnist_test_data.npz``.

    :raises FileNotFoundError: If ``mnist_test_data.npz`` is not found.

    :return: ``(test_images, test_labels)``, where ``test_images`` has shape ``(10000,
             12, 12)`` and ``test_labels`` has shape ``(10000,)``.
    """
    mnist_test_data_file = pathlib.Path(tensor_path) / "mnist_test_data.npz"
    if not mnist_test_data_file.exists():
        msg = f"{mnist_test_data_file} not found. Run tensorflow_training.py first."
        raise FileNotFoundError(msg)

    # Load MNIST test data.
    mnist_test_data = np.load(str(mnist_test_data_file))

    return mnist_test_data.get("test_images"), mnist_test_data.get("test_labels")


def batched_images(
    images: np.ndarray, start_image: int, num_images: int, batch_size: int
) -> typing.Iterator[tuple[int, np.ndarray]]:
    """Generator that yields batched image data.

    :param images: Image data to group into batches.
    :param start_image: Index of the first image in the first batch, in ``images``.
    :param num_images: Total number of images to yield. The yielded images may be
        grouped into batches, see ``batch_size`` below. The generator always stops at
        the end of ``images`` and does not wrap around to the beginning, so fewer than
        ``num_images`` images will be yielded if there aren't enough ``images``.
    :param batch_size: Maximum size of each batch. If ``num_images`` is not evenly
        divisible by ``batch_size``, the last batch will be a partial batch, with fewer
        than ``batch_size`` images. ``batch_size`` must be greater than zero.

    :raises ValueError: If ``start_image`` exceeds the number of available ``images``,
        or if ``batch_size`` is less than or equal to zero.

    :return: Yields ``batch_start_index, test_batch``, where ``batch_start_index`` is
             the index of the first image in the yielded batch, and ``test_batch`` is a
             batch of image data, with shape ``(batch_size, 12, 12)``. The last batch
             may be a partial batch with fewer than ``batch_size`` images, see the
             description of ``batch_size`` above. ``images[batch_start_index]`` is
             equivalent to ``test_batch[0]``.
    """
    if start_image >= len(images):
        msg = f"start_image must be less than the number of test images ({len(images)})"
        raise ValueError(msg)

    if batch_size <= 0:
        msg = "batch_size must be greater than zero"
        raise ValueError(msg)

    end_image = min(start_image + num_images, len(images))
    for batch_start_index in range(start_image, end_image, batch_size):
        batch_end_index = min(batch_start_index + batch_size, start_image + num_images)

        yield batch_start_index, images[batch_start_index:batch_end_index]


def preprocess_image(
    test_batch: np.ndarray, input_scale: np.ndarray, input_zero: np.ndarray
) -> np.ndarray:
    """Preprocess the raw image data in the batch. This is required by the quantized
    neural network.

    This adjusts the batch image data by ``input_scale`` and ``input_zero``. Then,
    it flattens each 2D image into a 1D column vector and stores them in a matrix of
    shape ``(144, batch_size)``.

    :param test_batch: Batch data to preprocess. This data should have already been
        normalized to ``[0.0, 1.0]`` and resized to ``(batch_size, 12, 12)``,
        usually by :func:`~pyrtlnet.mnist_util.load_mnist_images`.
    :param input_scale: Scale factor for ``test_batch``.
    :param input_zero: Zero point for ``test_batch``.

    :returns: Flattened batch data of shape ``(144, batch_size)``, adjusted by the
              quantized neural network's ``input_scale`` and ``input_zero``.
    """
    # The MNIST image data contains pixel values in the range [0, 255]. The neural
    # network was trained by first converting these values to floating point, in the
    # range [0, 1.0]. Dividing by input_scale below undoes this conversion,
    # converting the range from [0, 1.0] back to [0, 255].
    #
    # We could avoid these back-and-forth conversions by modifying
    # `load_mnist_images()` to skip the first conversion, and returning `x +
    # input_zero_point` below to skip the second conversion, but we do them anyway
    # to simplify the code and make it more consistent with existing sample code
    # like https://ai.google.dev/edge/litert/models/post_training_integer_quant
    #
    # Adding input_zero (-128) effectively converts the uint8 image data to int8, by
    # shifting the range [0, 255] to [-128, 127].
    test_batch = (test_batch / input_scale + input_zero).astype(np.int8)

    # Taking test_batch of shape (batch_size, 12, 12), each 2D matrix of shape
    # (12,12) is flattened to a 1D column vector of shape (144,), resulting in
    # test_batch's shape becoming (batch_size, 144). Then, we transpose, returning
    # the final shape (144, batch_size), where there are batch_size amount of column
    # vectors of shape (144,), each representing one image.
    return test_batch.reshape(test_batch.shape[0], -1).transpose()
